# 风力发电机组数据清洗系统技术流程说明文档

## 一、项目概述

本项目实现了一套基于空气密度修正的风力发电机组运行数据清洗系统，通过深度学习和自适应局部阈值方法，实现对风机异常数据的高精度识别与修正。

## 二、系统架构

### 2.1 模块组织结构

```
stage2_modular/
├── core/           # 核心功能模块
│   ├── device.py   # 设备管理（CPU/GPU自适应）
│   ├── utils.py    # 工具函数（数据读取、计时等）
│   ├── scaler.py   # 数据标准化器
│   ├── dmode.py    # 自适应尺度构造
│   └── splits.py   # 数据集划分
├── models/         # 预测模型
│   ├── center.py   # MLP中心模型
│   └── quantile.py # 分位数模型
├── thresholds/     # 阈值检测方法
│   ├── base.py     # 基础接口
│   ├── knn_local.py # KNN局部阈值（主算法）
│   ├── quantile_power.py
│   ├── quantile_zresid.py
│   └── registry.py # 方法注册器
└── pipeline/       # 流程编排
    └── orchestrator.py # 主流程控制器
```

### 2.2 数据流向

```
原始数据 → 数据读取与合并 → 风速范围筛选 → 空气密度融合 
→ 训练/验证集划分 → 数据标准化 → Pass1模型训练与预测 
→ 自适应尺度构造 → KNN局部阈值计算 → 异常标记 
→ Pass2模型精化 → 最终异常检测 → 结果输出
```

## 三、核心技术流程

### 3.1 数据获取与预处理

#### 3.1.1 数据读取（`utils.py`）
- **多编码兼容读取**：支持 UTF-8-sig、UTF-8、GBK、CP936 等多种编码
- **空气密度表合并**：从宽表中提取站点对应的空气密度列，按时间戳对齐
- **时间戳处理**：自动转换时间格式，去重并排序

```python
def load_rho_table(wide_csv: str, station: str):
    # 读取宽表数据
    # 查找空气密度列（支持多种命名："{站点}_空气密度"、"空气密度"、"rho"、"density"）
    # 按timestamp合并，处理重复与缺失
```

#### 3.1.2 风速范围筛选
- 根据配置的 `wind_scope`（默认 0-15 m/s）过滤数据
- 结合已有的规则1-5（Stage1产出）进一步筛选
- 构建 `S_scope` 作为有效分析范围

#### 3.1.3 额定功率估计
- 采用 **99.5% 分位数** 与实际最大值的较小者作为额定功率估计
- 用于后续的功率预测上限约束和自适应尺度计算

### 3.2 数据集划分与复用机制（`splits.py`）

#### 3.2.1 划分策略
支持三种策略：
1. **时间序列划分（time）**：按时间顺序划分，适用于时序相关性强的场景
2. **随机打散（shuffle）**：随机打散后划分，保证训练集和验证集分布一致
3. **分块打散（block_shuffle）**：按时间块（如天/周）打散，兼顾随机性与时序连续性

#### 3.2.2 持久化与复用
- 生成唯一的行键（timestamp + power + wind），确保可追溯
- 保存划分结果到 CSV（`_splits/` 目录）
- 支持跨实验复用相同划分，保证对比实验的公平性

```python
# 划分持久化机制
split_path = "{split_dir}/{station}/{turbine_id:03d}_{split_key}.csv"
save_split_csv(split_path, row_keys, idx_train, idx_val, idx_test)
```

### 3.3 数据标准化（`scaler.py`）

#### 3.3.1 标准化方法
支持两种标准化方法：
1. **MinMax 标准化（默认）**：
   - 风速范围：[0, 15] m/s → [0, 1]
   - 密度范围：[1.07, 1.37] kg/m³ → [0, 1]
   - 适用于固定物理范围的特征

2. **Z-Score 标准化**：
   - 基于训练集均值和标准差
   - 适用于分布未知或范围变化大的场景

#### 3.3.2 双空间标准化
系统维护**两套标准化空间**：
- **模型空间**（`_m` 后缀）：用于神经网络训练和预测
- **清洗空间**（`_c` 后缀）：用于KNN阈值计算

这样设计支持以下场景：
- 模型使用密度特征（`rho_for_model=true`）训练
- 清洗阶段不使用密度（`rho_for_clean=false`）
- 或反之，实现维度解耦

### 3.4 中心模型训练（Pass1）（`center.py`）

#### 3.4.1 模型架构
采用全连接神经网络（MLP）：
```
输入层：1维（仅风速）或 2维（风速+密度）
隐藏层：[512, 512, 256, 128]（可配置）
激活函数：ReLU / GELU / SiLU（可配置）
Dropout：0.05（防过拟合）
输出层：1维（预测功率）
```

#### 3.4.2 损失函数（`LossBuilder`）
支持三种损失函数：
1. **MSE（均方误差）**：标准回归损失
2. **wMSE（加权均方误差）**：根据自适应尺度 D 加权
3. **Huber-Z（稳健损失）**：在 z 空间（标准化残差空间）应用 Huber 损失

```python
# 加权损失
loss = mean(((pred - y_true)² / D²))

# Huber-Z 损失
z = (pred - y_true) / D
loss = smooth_l1_loss(z, 0, beta=delta_z)
```

#### 3.4.3 训练优化
- **自动混合精度（AMP）**：在GPU上使用FP16加速训练
- **早停机制**：验证集损失无改善时提前停止（patience=10）
- **GPU缓存模式**：数据量小于阈值时全部加载到GPU，避免频繁传输
- **流式模式**：数据量大时使用DataLoader按批次传输

### 3.5 自适应尺度构造（`dmode.py`）

#### 3.5.1 尺度定义
构造自适应尺度 `D`，作为后续 z-score 标准化的分母：

```python
D = max(y_hat, eps_ratio * P_rated, delta_power)
```

**参数说明**：
- `y_hat`：模型预测功率
- `eps_ratio * P_rated`：额定功率的小比例（如 5%），避免低功率区域过敏感
- `delta_power`：绝对功率阈值（如 50 kW），避免极小值

#### 3.5.2 四种模式
1. **pred_only**：仅使用预测值
2. **pred_or_epsPr**：预测值与额定功率比例的最大值
3. **pred_or_delta**：预测值与绝对阈值的最大值
4. **pred_or_both**（默认）：三者的最大值

**设计意图**：
- 低功率区：使用绝对阈值，避免噪声放大
- 中等功率区：使用预测值比例，随功率自适应
- 高功率区：直接使用预测值

### 3.6 KNN局部自适应阈值（Pass1）（`knn_local.py`）

#### 3.6.1 算法核心思想
传统全局阈值无法适应风机在不同运行状态下的差异，本算法通过**局部邻域**构造**自适应上下界**：

1. **Z-空间转换**：
   ```
   z_pos = max(residual, 0) / D
   z_neg = max(-residual, 0) / D
   ```

2. **邻域定义**：对每个查询点，在标准化空间中寻找K个最近邻（K=500）

3. **局部分位数**：在邻域内用加权分位数估计上下界
   ```
   thr_pos = weighted_quantile(z_pos[neighbors], weights, tau_hi)
   thr_neg = weighted_quantile(z_neg[neighbors], weights, tau_lo)
   ```

4. **Conformal标定**：在验证集上计算标定系数 `c_plus`, `c_minus`，保证覆盖率

#### 3.6.2 距离度量（Metric）
支持三种距离度量，适应不同场景：

**1. physics（物理距离）**：
- 基于风机功率物理模型 `P ≈ ρV³`
- 计算梯度方向：`∇P = (3ρV², V³)`（2维）或 `∇P = (3V²,)`（1维）
- 距离定义：法向距离（垂直于等功率线）
- 适用于：维度不匹配时的兜底策略

**2. grad_dir（梯度方向）**：
- 使用神经网络预测函数的梯度方向
- 支持两种梯度计算：
  - **autograd**（优先）：PyTorch自动微分，精确且快速
  - **finite difference**（回退）：有限差分，兼容性强
- 距离定义：垂直于预测曲面的法向距离

**3. tanorm（切法混合范数）**（默认推荐）：
- 结合法向距离和切向距离
- 距离公式：`d = sqrt(d_n² + λ_t * d_t²)`
- `d_n`：法向距离（残差方向）
- `d_t`：切向距离（沿等功率线方向）
- `λ_t`：切向权重（默认6.0）
- **创新点**：既考虑功率偏差，又考虑工况相似性

#### 3.6.3 GPU加速实现
- **批量查询**（BATCH_Q=16384）：一次处理多个查询点
- **候选分块**（TRAIN_CHUNK=131072）：避免显存溢出
- **行级TopK合并**：分块计算距离，逐步更新每行的K个最近邻
- **自动混合精度**：距离计算使用FP32保证精度，其他用FP16加速

```python
# 分块距离计算伪代码
for query_batch in queries:
    best_distances = [inf] * K
    best_indices = [-1] * K
    for candidate_chunk in candidates:
        distances = compute_distances(query_batch, candidate_chunk)
        # 合并到当前TopK
        merge_topk(best_distances, best_indices, distances, chunk_indices)
```

### 3.7 Pass2 精化

#### 3.7.1 训练集过滤
- 移除 Pass1 标记为异常的训练样本
- 使用清洁后的训练集重新训练模型

#### 3.7.2 二次异常检测
- 用新模型重新预测，计算残差和新的 D
- 再次运行 KNN 阈值算法
- 在 Pass1 未标记的样本中识别异常

#### 3.7.3 双重保险机制
- Pass1：粗筛，去除明显异常
- Pass2：精筛，在清洁数据上进一步识别隐藏异常
- 两次结果叠加，提高检测召回率

### 3.8 特征构造与输出

#### 3.8.1 输出字段
每个样本生成以下字段：
- `pred_center_p1`：Pass1 预测功率
- `pred_center`：Pass2 预测功率（最终）
- `residual`：最终残差（实际功率 - 预测功率）
- `D`：自适应尺度
- `thr_pos`：正向阈值（上界）
- `thr_neg`：负向阈值（下界）
- `Pass1_异常`：Pass1 异常标记（布尔）
- `Pass2_异常`：Pass2 异常标记（布尔）
- `exceed_ratio`：超限比例（`max((r-thr_pos)/thr_pos, (-r-thr_neg)/thr_neg)`）
- `split`：所属集合（train/val/test）

#### 3.8.2 结果保存
- 按站点和风机号组织目录：`{out_root}/{run_tag}/{station}_mlp/{tid}号机/`
- CSV 格式，UTF-8-sig 编码（兼容 Excel）
- 保留原始数据所有列，追加清洗结果列

## 四、配置与实验管理

### 4.1 配置结构（JSON）
```json
{
  "defaults": {
    "stage1_root": "...",
    "out_root": "...",
    "device": "cuda:0",
    "split": {...},
    "scaler": {...},
    "mlp": {...},
    "thresholds": {...}
  },
  "stations": [
    {"name": "站点1", "csv": "...", "turbine_start": 1, "turbine_end": 10}
  ],
  "runs": [
    {
      "name": "实验1",
      "rho_for_clean": true,
      "rho_for_model": true,
      "rho_input_mode": "normal",
      "thresholds": {"method": "knn", "metric": "tanorm"}
    }
  ]
}
```

### 4.2 多实验批量执行
- 支持一次配置多个实验（runs）
- 自动复用划分（`reuse_split_from`）保证公平对比
- 每个实验独立输出目录

### 4.3 空气密度使用模式
**rho_input_mode**：
- `normal`：直接使用实测密度
- `constant`：使用常数密度（如训练集均值）
- `shuffle`：随机打散密度值（消融实验）

**应用场景**：
- 验证密度特征对模型性能的贡献
- 研究密度与功率的因果关系

## 五、关键设计亮点

### 5.1 维度解耦设计
- 清洗阶段（KNN）和建模阶段（MLP）可以使用**不同维度**的特征
- 例如：模型用 [风速, 密度]，清洗只用 [风速]
- 通过 `grad_mode='physics'` 自动兜底，避免维度不匹配导致的错误

### 5.2 自动回退机制
- Autograd 优先 → Finite Difference 回退 → Physics 兜底
- GPU 优先 → CPU 回退
- 确保在各种环境下都能正常运行

### 5.3 显存管理
- 根据数据量自动选择 GPU-Cached 或 Streaming 模式
- 候选集分块，查询批量处理
- 及时释放中间张量，调用 `torch.cuda.empty_cache()`

### 5.4 可复现性保障
- 全局随机种子控制
- 数据划分持久化
- 训练过程确定性（设置 `torch.backends.cudnn.benchmark`）

## 六、技术指标

### 6.1 性能指标
- **单风机处理时间**：约 10-60 秒（取决于数据量和硬件）
- **GPU加速比**：相比CPU约 5-20 倍
- **内存占用**：训练模式约 2-20 GB（取决于数据量和缓存模式）

### 6.2 精度指标
- **异常检测覆盖率**：通过 Conformal 标定保证验证集覆盖率达到 τ（如 98%）
- **误报率**：通过两阶段过滤降低误报
- **模型 R²**：通常达到 0.95+ （取决于风机和工况）

## 七、技术依赖

### 7.1 核心库
- **NumPy**：数值计算
- **Pandas**：数据表处理
- **PyTorch**：深度学习框架，GPU 加速
- **CUDA**（可选）：GPU 计算

### 7.2 版本要求
- Python 3.8+
- PyTorch 1.12+（支持 AMP 和 autograd）
- NumPy 1.20+
- Pandas 1.3+

## 八、扩展性与可维护性

### 8.1 模块化设计
- 清晰的模块边界，低耦合
- 通过注册器（`registry.py`）动态加载算法
- 新增阈值方法只需继承 `ThresholdMethod` 并注册

### 8.2 配置驱动
- 所有超参数通过 JSON 配置
- 无需修改代码即可调整实验
- 便于参数搜索和对比实验

### 8.3 日志与调试
- 详细的时间统计（`Stopwatch`）
- 关键步骤打印日志
- 异常时给出明确的错误提示和参数信息

---

## 附录：术语表

| 术语 | 含义 |
|-----|------|
| Pass1/Pass2 | 两阶段清洗流程 |
| z-space | 标准化残差空间（residual / D） |
| D | 自适应尺度（Adaptive Scale） |
| τ (tau) | 分位数水平（如 0.98） |
| Conformal Prediction | 保形预测（一种校准方法） |
| tanorm | 切法混合范数（Tangent-Normal Hybrid Norm） |
| P_rated | 额定功率 |
| scope | 分析范围（过滤后的有效数据） |
| rho | 空气密度（kg/m³） |
| AMP | 自动混合精度（Automatic Mixed Precision） |

---

**文档版本**：1.0  
**生成时间**：2026-02-04  
**适用代码版本**：stage2_modular
