# 风电数据清洗实验方案报告（考虑空气密度）

> **版本**：v2.2 · **时间**：2026-02  
> **适用对象**：论文作者、合作同学、审稿人参考  
> **配套文件**：`experiments_paper_ablation.json`（实验运行配置）、`stage2_modular/evaluation/`（评估模块）

---

## 目录

0. [作者问答（Q&A）](#0-作者问答qa)  
   - Q1：训练集和验证集各自的作用是什么？  
   - Q2：划分持久化与复用是如何保证的？  
   - Q3：为什么要分为 rho_for_model 和 rho_for_clean？  
   - Q4：清洗用 MLP（MSE 损失），验证也用 RMSE，这样合理吗？  
   - Q5：训练 MLP 时用了 val 集做早停，那最后为什么不能用 val RMSE 来判断？  
   - Q6：A_rules_only 只有部分风机结果，其余缺失，是什么原因？  
1. [研究背景与动机](#1-研究背景与动机)  
2. [核心方法说明](#2-核心方法说明)  
   - 2.1 空气密度的物理意义  
   - 2.2 两阶段清洗框架  
   - 2.3 KNN 局部分位阈值  
   - 2.4 空气密度的两种引入方式  
3. [实验设计总表](#3-实验设计总表)  
4. [各组实验详细说明](#4-各组实验详细说明)  
5. [数据集划分策略](#5-数据集划分策略)  
6. [评价指标体系](#6-评价指标体系)  
7. [风险与注意事项清单](#7-风险与注意事项清单)  
8. [论文结构建议](#8-论文结构建议)  
9. [代码使用指引](#9-代码使用指引)  

---

## 0. 作者问答（Q&A）

> 本节直接回答作者在讨论中提出的具体问题，供快速参考。

---

### Q1：训练集和验证集各自的作用是什么？

**训练集（train）** 和 **验证集（val）** 在本框架中承担三层不同的角色：

#### 第一层：MLP 模型训练（梯度层）

| 集合 | 作用 |
|------|------|
| 训练集 | 提供样本参与反向传播，更新 MLP 权重 |
| 验证集 | **不参与梯度更新**，仅用于每个 epoch 后计算 `val_loss`，驱动 early stopping |

训练过程中，每当 `val_loss` 创新低时，模型状态（`best_state`）就会被保存；连续 `patience=20` 个 epoch 没有改善时停止训练，并恢复到最优状态。**验证集的作用是防止过拟合，而非参与学习。**

```
epoch 1 → val_loss=0.0412  ← 记录 best_state
epoch 2 → val_loss=0.0398  ← 更新 best_state
...
epoch 47 → val_loss=0.0391 ← 更新 best_state
epoch 48 → val_loss=0.0394
...
epoch 67 → val_loss=0.0403 ← 连续 20 epoch 无改善 → 停止，恢复 epoch 47 的权重
```

#### 第二层：KNN 清洗的参考分布（清洗层）

| 集合 | 作用 |
|------|------|
| 训练集 | 建立 KNN 参考分布，即所有 $K$ 近邻都从训练集中搜索 |
| 验证集 | **不参与 KNN 参考分布的构建**，其异常判断是纯外推 |

KNN 清洗时，对任意查询点（无论是训练点还是验证点），都从**训练集**中找 $K=500$ 个最近邻，计算局部分位阈值，判断该查询点是否异常。因此：
- 训练点的异常判断：用训练集中"排除自身"的邻居（或包含自身，视实现而定）
- 验证点的异常判断：完全依赖训练集的分布，**验证集未参与阈值构建**，保证了独立性

#### 第三层：最终评估（评估层）

| 集合 | 作用 |
|------|------|
| 训练集 | 最终训练数据（Pass2 之后的干净训练点），不直接用于评估 |
| 验证集 | 用于早停和 val_loss 曲线展示，**不作为最终对外指标**（已参与模型选择，见 Q5） |
| **测试集** | **报告最终 RMSE/MAE/R²**，是对外宣称的指标来源；从未参与任何训练或选择决策 |

> **小结**：验证集不参与梯度更新，也不参与 KNN 参考分布构建；但它**参与了模型选择（early stopping）**，因此 val RMSE 并非完全独立的评估。最终对外报告的指标必须使用**测试集（test）**，详见 [Q5](#q5训练mlp时用了val集做早停那最后为什么不能用-val-rmse-来判断应该用-test-吗)。

---

### Q2：划分持久化与复用是如何保证的？

**核心机制**：每行数据用 `timestamp(ns) + '#' + row_index` 生成唯一的稳定键（`row_key`），划分结果保存为 CSV，后续实验通过键值匹配对齐。

#### 保存（A 组运行时）

```
row_key                      split
1693440000000000000#0        train
1693440060000000000#1        val
1693440120000000000#2        train
...
```

保存到：`paper_ablation_runs/_splits/JMZSFD_51号机_v1.csv`

#### 加载（B、C、D、E ... 组运行时）

```python
# splits.py 核心逻辑（简化）
kv = dict(zip(persisted["row_key"], persisted["split"]))
splits_now = [kv.get(key, "train") for key in current_row_keys]
```

1. 对当前 DataFrame 的每行生成同样规则的 `row_key`
2. 在持久化 CSV 中查找该 key 对应的 split 标签
3. 找不到的行（如 rho 缺失导致某行在 B 组被 drop）默认归为 `train`

#### 关键保障

| 保障点 | 具体机制 |
|--------|---------|
| 行顺序无关 | key 基于 timestamp，不依赖行号，即使 DataFrame 过滤后行号变化也能正确对齐 |
| rho 缺失不影响 | 若 B 组因 rho 缺失比 A 组少若干行，缺失行默认 train，不会错误划分 |
| 确定性 | 同一份数据、同一个 seed，每次生成的 row_key 完全相同 |
| 全局统一 | B–J 所有实验的 JSON 中均配置 `reuse_split_from: "A_rules_only"`，orchestrator 统一加载 A 组的划分文件 |

> **效果**：B、C、D、E 等组**看到完全相同的训练集和验证集**（指相同的时间戳样本），保证消融对比的公平性——性能差异只来自方法本身，而非数据划分差异。

---

### Q3：为什么要分为 `rho_for_model` 和 `rho_for_clean`？

这两个开关对应的是**空气密度进入系统的两个完全不同的位置**，作用机制不同，贡献不能相互替代。

#### `rho_for_model`：影响中心预测 ŷ 的准确性

```
输入层：[wind_std, rho_std] → MLP → ŷ（功率预测）
残差：r = y - ŷ
```

- **True 时**：MLP 学习二维功率曲面 $\hat{P}(V, \rho)$，密度高时预测更高功率
- **False 时**：MLP 只学习一维功率曲线 $\hat{P}(V)$，密度引起的功率变化会进入残差 $r$，使残差分布变宽

**结果**：`rho_for_model=True` 让残差更小、更集中，KNN 的阈值更紧致，**减少漏报**（异常点的残差更显著）。

#### `rho_for_clean`：影响 KNN 邻域的定义

```
KNN 搜索空间：[wind_std, rho_std]（2D）或 [wind_std]（1D）
目的：找"工况相似"的训练点，估计该工况下的局部分位
```

- **True 时**：邻域搜索同时匹配风速和密度，"密度 1.35 kg/m³、风速 8 m/s"只和同类工况的点比较
- **False 时**：邻域只匹配风速，"密度 1.35 kg/m³、风速 8 m/s"和"密度 1.10 kg/m³、风速 8 m/s"的点混在一起比较，阈值被低密度工况的分布稀释

**结果**：`rho_for_clean=True` 让每个工况的异常判断更"因地制宜"，**减少误报**（高密度工况的正常高功率不被低密度邻居拉低的阈值误判为异常）。

#### 两者互补，拆开才能量化各自贡献

| 实验 | `rho_for_model` | `rho_for_clean` | 揭示 |
|------|:-:|:-:|------|
| B | ✗ | ✗ | 无密度基准 |
| C | ✓ | ✗ | 仅"预测更准"的贡献 |
| D | ✗ | ✓ | 仅"邻域更公平"的贡献 |
| E | ✓ | ✓ | 两者叠加 |

若设计为"要么都用要么都不用"，就无法分辨 C 和 D 各自的独立价值，消融实验失去意义。

---

### Q4：清洗用 MLP（MSE 损失），验证也用 RMSE，这样合理吗？

这个问题问得非常关键。**简短回答：有一定合理性，但存在需要正视的局限性。**

#### 先厘清"MSE 损失"和"RMSE 指标"的角色差异

| | 发生阶段 | 数据集 | 目的 |
|--|---------|--------|------|
| **MSE 损失**（训练） | 清洗阶段（内部） | 训练集 | 优化 MLP 权重，获得准确的中心估计 ŷ |
| **RMSE 指标**（评估） | 验证阶段（外部） | 验证集（干净点） | 衡量最终功率曲线模型的预测精度 |

两者**测量的是不同数据集上的同类误差**，不是在同一个集合上做循环自评。

#### 独立性来源

```
训练集（含噪）
    → MLP 训练（MSE loss）→ 得到 ŷ
    → KNN 清洗 → 标记异常 → 得到干净训练集
    → 用干净训练集重训 MLP（Pass 2）
    → 最终模型 f*(·)

验证集（从未参与任何训练或阈值决策）
    → 用 f*(·) 预测 → 计算 RMSE
```

验证集的 RMSE 评估的是：**经过完整清洗流程后得到的模型 f\***，在"它从未见过的数据"上的精度。这与传统机器学习的 train/val 独立评估逻辑完全一致。

#### 潜在问题：清洗结果与评估指标之间的软耦合

即使验证集独立，仍存在一个软性循环：

> **清洗方法本身（MLP+MSE）和评估指标（RMSE）都隐含了"最小化 $L_2$ 误差"的偏好。**  
> 如果方法 E 倾向于保留"容易用 $L_2$ 拟合的点"、剔除"难拟合的点"，那么 RMSE 改善可能来自"回避难点"而非真正更好的清洗。

换句话说：**用同一把尺子来设计清洗工具，再用同一把尺子来衡量清洗效果，存在先天的乐观偏差。**

#### 如何缓解这一问题

| 措施 | 说明 |
|------|------|
| **同时报告 MAE 和 R²** | MAE 对异常值不敏感，R² 与量纲无关；若三个指标方向一致，可信度更高 |
| **监控清洗率** | 若方法 E 的清洗率远高于 B（如多剔除 10%），需质疑是否过度清洗 |
| **对全量验证集也计算 RMSE** | 不排除异常标记点，看"含脏点"和"仅干净点"的 RMSE 差距是否合理 |
| **F/G 消融组的交叉验证作用** | rho_shuffle（F）和 rho_constant（G）的清洗率与 E 相近，但 RMSE 若明显差于 E，说明性能提升不来自"回避难点" |
| **（如可能）引入物理核查** | 对检出的异常点人工抽检，确认确实是有问题的数据点 |

> **结论**：当前阶段（无人工标注），RMSE 是能用的最合理代理指标，但需要**配合清洗率、多指标、消融组**共同解读，不能单独以 RMSE 改善来宣称方法优越。

---

### Q5：训练 MLP 时用了 val 集做早停，那最后为什么不能用 val RMSE 来判断？应该用 test 吗？

**是的，你的判断完全正确。**

#### 问题的根源：early stopping 使 val 数据参与了模型选择

在 `fit_mlp_center` 中，每个 epoch 结束后都会在 val 集上计算 `val_loss`，并用它来决定保存哪个 checkpoint：

```python
# center.py 中 fit_mlp_center 的核心逻辑
if vloss + 1e-9 < best:
    best = vloss
    bad = 0
    best_state = {k: v.clone() for k, v in model.state_dict().items()}  # ← 基于 val_loss 保存最优权重
else:
    bad += 1
    if bad >= patience: break  # ← 基于 val_loss 决定停止时机
```

最终返回的模型 `f*` 是 val_loss 最低的那个 checkpoint——它被选出来**正是因为**在 val 上表现好。所以 val RMSE 不是对 `f*` 泛化能力的无偏估计：`f*` 在 val 上表现好，部分原因就是它是专门为 val 选出来的。

这种现象叫做 **"模型选择偏差"（model selection bias）**：val 数据通过调参/选模型影响了最终模型，再用它来评估就形成了隐性循环。

#### val RMSE 偏差有多严重？

与直接在训练集上评估相比，val set 的模型选择偏差通常要小得多，但仍然存在：

| 评估方式 | 偏差程度 | 原因 |
|---------|---------|------|
| 训练集 RMSE | **最严重**（极度乐观） | 模型直接在此集上优化梯度 |
| 验证集 RMSE | **中等**（模型选择偏差） | val_loss 驱动了早停和最优 checkpoint 选择 |
| **测试集 RMSE** | **最可靠**（无偏估计） | test 完全未参与任何训练和选择决策 |

#### 正确的三分法

```
全部数据
  ├── train（70%）：梯度更新（反向传播）← 唯一参与权重更新的集合
  ├── val  （15%）：早停 + 选最优 checkpoint ← 允许展示 val_loss 曲线，但不作为最终指标
  └── test （15%）：最终 RMSE / MAE / R² ← 完全独立，仅在所有训练结束后一次性读入评估
```

**test 集的"完全独立"**意味着：test 中的样本不参与梯度更新、不参与早停、不参与模型选择、也不参与 KNN 参考分布构建，只在所有训练完成后一次性用于指标计算。

#### 对本项目的修正

1. **配置文件**中的默认划分比例已从 `[0.8, 0.2, 0.0]` 更新为 `[0.70, 0.15, 0.15]`：

   ```json
   "split": { "strategy": "shuffle", "ratio": [0.70, 0.15, 0.15] }
   ```

2. **代码层面**无需改动：`orchestrator.py` 已正确将 test 样本标注为 `split="test"`，并完全不将其用于梯度更新或 KNN 参考分布；`metrics.py` 中 `compute_model_metrics(..., split="test")` 也已实现。

3. **评估和报告**中统一使用 `split="test"` 作为最终指标来源（见 §6.2、§9.2）。

> **注意**：当单台风机的总样本量较少时，15% 的 test 集约为几百条，RMSE 方差会较大。建议将多台风机的 test 集合并后统一计算，或报告各台风机 test RMSE 的均值 ± 标准差，以增加统计可靠性。

---

### Q6：A_rules_only 文件夹中只有 1号机、11号机、21号机、31号机、41号机、51号机的结果，其余风机的结果缺失，是什么问题？

#### 根本原因：`turbine_start` / `turbine_end` 配置范围不完整

`orchestrator.py` 用以下逻辑决定处理哪些风机：

```python
for tid in range(int(st_cfg["turbine_start"]), int(st_cfg["turbine_end"]) + 1):
    in_masks = f"{stage1_dir}/{station}_{tid}号机_masks.csv"
    if not os.path.exists(in_masks):
        print(f"⚠ 未找到 {in_masks}，跳过")
        continue
    # 处理 tid 号机 ...
```

**关键点**：代码只会在 `range(turbine_start, turbine_end+1)` 这个整数区间内循环，循环范围之外的风机编号**从不尝试**，因此也永远不会产生"未找到文件"的警告——它们直接被忽略。

若配置为 `turbine_start=1, turbine_end=1`（每个站点只配置了 1 台风机），则其余风机（2号机、3号机……）即使有完整的 Stage 1 masks 文件也不会被处理，输出目录里就只会出现 `1号机/`。

**结果**：6 个站点各只配置了 1 台风机（1、11、21、31、41、51），所以输出正好是这 6 台。

#### 解决方案：使用 `turbine_auto_discover`

已在 `orchestrator.py` 中新增自动发现逻辑。当站点配置中设置 `"turbine_auto_discover": true` 时，代码会扫描 `stage1_dir` 中所有符合 `{站点名}_N号机_masks.csv` 命名规则的文件，自动确定要处理的风机编号列表，无需手动维护 `turbine_start`/`turbine_end`。

**优先级规则**（按顺序）：

| 优先级 | 配置方式 | 行为 |
|-------|---------|------|
| 1 | `"turbine_auto_discover": true` | 扫描目录，自动发现所有 masks 文件对应的风机号 |
| 2 | `"turbine_ids": [1, 5, 10]` | 直接使用指定的编号列表 |
| 3 | `"turbine_start": N, "turbine_end": M` | 使用 `range(N, M+1)`（兼容旧配置） |

#### 修改后的 JSON 配置

`experiments_paper_ablation.json` 中的站点配置已更新：

```json
"stations": [
  {
    "name": "JMZSFD",
    "csv": "JMZSFD_空气密度_20230921-20240729_1min.csv",
    "turbine_auto_discover": true
  }
]
```

如果有多个站点（风场），每个站点均可加上 `"turbine_auto_discover": true`：

```json
"stations": [
  {"name": "StationA", "csv": "StationA_空气密度_....csv", "turbine_auto_discover": true},
  {"name": "StationB", "csv": "StationB_空气密度_....csv", "turbine_auto_discover": true},
  ...
]
```

#### 运行时输出示例

开启自动发现后，每个站点会打印类似以下的日志：

```
[AutoDiscover] JMZSFD: 共发现 58 台风机 → [1, 2, 3, ..., 56, 57, 58]
>>> 处理 JMZSFD 1号机 ...
>>> 处理 JMZSFD 2号机 ...
...
>>> 处理 JMZSFD 58号机 ...
```

> **注意**：若目录中某些风机的 Stage 1 masks 文件确实不存在（Stage 1 未完成），代码仍会打印 `⚠ 未找到 XXX，跳过` 并继续处理其余风机，不会中断整个流程。

### 1.1 问题来源

风机的功率输出不仅受风速影响，还与空气密度 $\rho$（由温度 $T$、气压 $P$、相对湿度 $RH$ 共同决定）密切相关。根据空气动力学：

$$P \approx \frac{1}{2} C_p \rho A V^3$$

其中 $C_p$ 为风能利用系数，$A$ 为叶轮扫风面积，$V$ 为风速。这意味着：

- **相同风速下**，密度高时（如冬季低温高压），理论功率应更高；
- **忽略密度**的功率曲线模型会将密度引起的功率波动误判为噪声或异常；
- 传统清洗方法仅用风速作为输入特征，无法区分"真正的脏点"与"密度差异引起的合理偏差"。

### 1.2 核心问题

| 问题编号 | 待回答问题 |
|----------|-----------|
| Q1 | 引入空气密度后，清洗质量（异常检出率、误判率）是否稳定提升？ |
| Q2 | 性能提升主要来自"密度辅助清洗"还是"密度辅助建模"？ |
| Q3 | 密度信息必须是真实逐时值，还是用均值/乱序替代也能获益？ |
| Q4 | 两次迭代清洗相比单次有多大改善？ |

---

## 2. 核心方法说明

### 2.1 空气密度的物理意义

空气密度由湿空气状态方程计算：

$$\rho = \frac{P_d}{R_d T} + \frac{P_v}{R_v T}$$

其中 $P_d$ 为干空气分压，$P_v$ 为水汽分压，$R_d = 287.05$，$R_v = 461.5$（单位 J·kg⁻¹·K⁻¹）。项目已实现从原始气象数据（$T, P, RH$）逐时计算 $\rho$，并存储于宽表 CSV（字段名格式：`{站点名}_空气密度`）。

典型值范围：**1.07 ～ 1.37 kg/m³**（已在 `Scaler` 中设为归一化边界）。

### 2.2 两阶段清洗框架

```
原始数据
    │
    ▼
Stage 1（规则清洗）
  ├─ 规则1：功率为负
  ├─ 规则2：风速超出运行区间
  ├─ 规则3：功率/风速组合明显违反物理
  ├─ 规则4：功率突变（限电/故障）
  └─ 规则5：维护停机标志
    │
    ▼  输入：wind, power[, rho]
Stage 2（MLP + KNN 模型清洗）
  │
  ├─ Pass 1：用全量训练数据训练 MLP 中心模型 → 得到残差 r = y - ŷ
  │           KNN 局部分位阈值 → 标记 Pass1_异常
  │
  └─ Pass 2：用剔除 Pass1_异常后的干净训练数据重新训练 MLP
              KNN 局部分位阈值（更干净的参考分布）→ 标记 Pass2_异常
    │
    ▼
清洗后干净数据集（用于功率曲线建模、功率预测）
```

**Pass 2 的必要性**：Pass 1 的 MLP 在含噪训练数据上训练，中心估计 ŷ 会被少量极端脏点拉偏，导致部分真实异常点的残差偏小（被脏点"拉近"），漏报。Pass 2 剔除已知异常点后重训，得到更准确的 ŷ，能发现 Pass 1 遗漏的隐性异常。

### 2.3 KNN 局部分位阈值

与传统全局分位不同，本方案对每个查询点 $x_q$ 在特征空间中寻找 $K=500$ 个最近邻训练点，以**加权分位**估计该点的局部上下界：

$$\hat{q}^+_{x_q} = \text{WeightedQuantile}(\{z^+_i\}_{i\in\mathcal{N}(x_q)},\, w_i,\, \tau^+)$$

其中 $z^+ = \max(r, 0) / D$，$D$ 为基于预测值的自适应尺度，$w_i = \exp(-d_i^2 / (2\sigma^2))$ 为高斯核权重。

距离度量支持三种模式（可在配置中选择）：

| 度量 | 含义 | 适用场景 |
|------|------|---------|
| `tanorm` | 切向距离 + 法向距离加权（$\lambda_t$ 控制比例） | 默认，兼顾位置和功率方向 |
| `grad_dir` | 纯法向距离（梯度方向） | 关注功率曲线法向偏差 |
| `physics` | 基于物理 $P\propto\rho V^3$ 的等功率面距离 | 物理先验强时使用 |

### 2.4 空气密度的两种引入方式

本项目将"引入密度"拆分为两个独立的开关，便于消融（详见 [Q3 问答](#q3为什么要分为-rho_for_model-和-rho_for_clean)）：

| 开关 | 影响位置 | 具体作用 |
|------|---------|---------|
| `rho_for_model` | MLP 输入层 | 让功率预测 ŷ 感知密度，残差更小更集中 |
| `rho_for_clean` | KNN 特征空间 | 让邻域搜索匹配密度，阈值更"因地制宜" |

两个开关独立组合，产生四种模式（见第 3 节实验 B/C/D/E）。

---

## 3. 实验设计总表

| 实验 ID | 名称 | 清洗次数 | `rho_for_clean` | `rho_for_model` | rho 输入模式 | 核心目的 |
|---------|------|----------|----------------|----------------|-------------|---------|
| **A** | `A_rules_only` | 0 | ✗ | ✗ | — | **基准线**：仅规则清洗，无 MLP |
| **B** | `B_no_rho` | 2 | ✗ | ✗ | — | 无密度的 MLP 清洗基准 |
| **C** | `C_rho_model_only` | 2 | ✗ | ✓ | normal | 密度仅用于建模，清洗不用 |
| **D** | `D_rho_clean_only` | 2 | ✓ | ✗ | normal | 密度仅用于清洗邻域，建模不用 |
| **E** | `E_rho_both` | 2 | ✓ | ✓ | normal | **完整方案**：清洗+建模均用密度 |
| **F** | `F_rho_shuffle` | 2 | ✓ | ✓ | **shuffle** | 消融：打乱 rho 时序，验证信息有效性 |
| **G** | `G_rho_constant` | 2 | ✓ | ✓ | **constant** | 消融：用均值替代 rho，验证密度变化的作用 |
| **J** | `J_one_pass_rho_both` | **1** | ✓ | ✓ | normal | 消融：单次 vs. 两次迭代清洗 |
| H/I | *(季节泛化，暂不讨论)* | — | — | — | — | 留待后续研究 |

> **对比逻辑**：  
> - A vs B：MLP 清洗本身的价值  
> - B vs E：空气密度的整体贡献  
> - B vs C：`rho_for_model` 的独立贡献（仅改善中心预测）  
> - B vs D：`rho_for_clean` 的独立贡献（仅改善邻域定义）  
> - C vs E 与 D vs E：两种引入方式的互补性  
> - E vs F：rho 的逐时精确值是否真正有效（排除"维度扩充"假象）  
> - E vs G：密度**变化量**的贡献（排除均值偏置效应）  
> - E vs J：两次迭代清洗的增量价值

---

## 4. 各组实验详细说明

### A — 仅规则清洗（基准）

Stage 1 的五条规则清洗后，直接输出结果，不经过任何 MLP 建模。  
**作用**：提供最朴素的基准，量化 Stage 2（MLP+KNN）本身带来的清洗增益。  
所有使用 `reuse_split_from: "A_rules_only"` 的后续实验均复用本组的数据划分，确保比较公平（详见 [Q2 问答](#q2划分持久化与复用是如何保证的)）。

### B — 无空气密度的 MLP 清洗

仅以风速为特征（`in_dim=1`），KNN 在 1D 风速空间中搜索邻域。  
KNN 距离度量设为 `grad_mode: physics`（退化为纯风速梯度方向，即等风速线），不需要 autograd 求梯度。  
**作用**：建立引入密度前的 MLP 清洗基准，与 E 组对比衡量密度的总体价值。

### C — 密度仅用于 MLP 建模

MLP 输入为 `[wind_std, rho_std]`（2D），预测功率曲面更精确；  
但 KNN 清洗邻域搜索仍在 1D 风速空间（`rho_for_clean=false`），距离度量用物理方向。  
**预期**：中心模型残差分布更集中，阈值更紧致，清洗精度有所提升，但不如 E 组（邻域定义仍不考虑密度）。

### D — 密度仅用于清洗邻域

KNN 以 `[wind_std, rho_std]` 为 2D 特征空间搜索邻域（密度相近的点聚在一起），阈值更具密度感知能力；  
但 MLP 仍只用风速（1D），中心预测精度不如 E 组。  
**预期**：清洗误报率（正常高密度点被误判）有所下降，但因中心模型不准，漏报可能仍较多。

### E — 完整方案（清洗+建模均用密度）

所有组件均使用密度：MLP 输入 2D，KNN 邻域搜索 2D，梯度方向通过 `autograd` 自动计算。  
**这是论文的主要方法**，预期在所有指标上优于 B/C/D。

### F — rho Shuffle 消融

保持完整方案（E）结构，但将 `rho` 序列**随机打乱**（保持同 split 内统计分布不变，但时序对应关系破坏）。  
- 若 F 与 E 性能接近 → 说明密度的提升来自统计分布而非逐时精确值，可信度存疑；  
- 若 F 明显差于 E → 说明 rho 的逐时精确值确实携带有效信息，方法可信。

### G — rho Constant 消融

将 rho 替换为训练集均值（一个固定标量），送入所有样本。  
- 若 G ≈ B（无密度）→ 说明密度的作用在于其**逐时变化**，而非平均水平；  
- 若 G 优于 B 但差于 E → 说明均值偏置有少量帮助，但时变信息更关键。

### J — 单次 vs. 两次迭代清洗

只执行 Pass 1，不进行 Pass 2 重新训练和二次检测。  
**作用**：衡量两次迭代设计的增量价值，评估额外的计算成本是否值得。

---

## 5. 数据集划分策略

### 5.1 随机打乱（shuffle，默认）

```json
"split": { "strategy": "shuffle", "ratio": [0.70, 0.15, 0.15] }
```

70% 训练 / 15% 验证 / 15% 测试，随机打乱后按比例切分。  
**验证集**仅用于 MLP 早停和 val_loss 监控；**测试集**是最终 RMSE/MAE/R² 报告的唯一来源。  
适用于 i.i.d. 假设下的模型精度评估。

### 5.2 时序划分（time）

```json
"split": { "strategy": "time", "ratio": [0.70, 0.15, 0.15] }
```

按时间顺序切分，前 70% 训练，中 15% 验证，后 15% 测试。  
模拟实际部署中"过去训练、未来预测"的场景，但会引入季节不均衡。

### 5.3 块随机（block_shuffle）

```json
"split": { "strategy": "block_shuffle", "block_freq": "D" }
```

以天（或其他频率）为单位打乱，保持同天数据在同一分组，避免相邻时刻数据泄漏到不同分组。

### 5.4 划分持久化与复用

所有划分结果以 `row_key = timestamp(ns) + '#' + index` 为键持久化到 CSV，后续 run 可通过 `reuse_split_from` 复用相同划分，确保不同实验的训练/验证集完全一致（详见 [Q2 问答](#q2划分持久化与复用是如何保证的)）。

---

## 6. 评价指标体系

评估分为两个层次：

```
① 清洗质量评估（代理指标：清洗率、保留率）
      ↓
② 功率曲线建模精度（test 集：RMSE / MAE / R²）
```

### 6.1 清洗质量指标

| 指标 | 含义 | 计算方式 |
|------|------|---------|
| `rate_pass1` | Pass 1 异常率 | Pass1_异常 数 / scope 样本数 |
| `rate_pass2` | Pass 2 增量异常率 | Pass2_异常 数 / scope 样本数 |
| `rate_total_abn` | 总异常率（P1 ∪ P2） | (P1_abn ∪ P2_abn) / scope |
| `rate_clean` | 清洗后保留率 | 1 - rate_total_abn |
| `n_scope` | 有效样本数 | 规则通过 & 风速在范围内 |

> **注**：当前缺少人工标注的异常真值，无法直接计算 Precision/Recall。清洗率是间接反映清洗力度的代理指标，需配合建模指标共同解读（详见 [Q4 问答](#q4清洗用-mlpmse-损失验证也用-rmse这样合理吗)）。

### 6.2 建模精度指标

在**测试集**的**干净点**（排除 Pass1/Pass2 异常标记）上计算（见 [Q5](#q5训练mlp时用了val集做早停那最后为什么不能用-val-rmse-来判断应该用-test-吗)）：

| 指标 | 含义 | 公式 |
|------|------|------|
| RMSE | 均方根误差（功率，kW） | $\sqrt{\frac{1}{n}\sum(y_i - \hat{y}_i)^2}$ |
| MAE | 平均绝对误差（功率，kW） | $\frac{1}{n}\sum\|y_i - \hat{y}_i\|$ |
| R² | 决定系数 | $1 - \frac{\sum(y-\hat{y})^2}{\sum(y-\bar{y})^2}$ |

**同时建议报告**：在测试集**全量点**（含异常标记点）上的 RMSE，与"仅干净点 RMSE"对比，确认清洗效果来自真实改善而非回避难点（见 [Q4 分析](#q4清洗用-mlpmse-损失验证也用-rmse这样合理吗)）。

### 6.3 使用评估模块

```python
from stage2_modular.evaluation import summarize_run, compare_runs

run_names = ["A_rules_only", "B_no_rho", "C_rho_model_only",
             "D_rho_clean_only", "E_rho_both", "F_rho_shuffle",
             "G_rho_constant", "J_one_pass_rho_both"]

results = {
    name: summarize_run(f"paper_ablation_runs/{name}", split="test")   # ← test，非 val
    for name in run_names
}

# 主对比表格（含 RMSE/MAE/R²/清洗率）
table = compare_runs(results)
print(table.to_markdown())   # 可直接粘贴到 Markdown 文档
```

---

## 7. 风险与注意事项清单

| 风险项 | 描述 | 应对措施 |
|--------|------|---------|
| **val 集模型选择偏差** | MLP 早停使用 val_loss 选择 checkpoint，val RMSE 是乐观估计 | 已改用三分法（70/15/15）；对外指标统一使用 test 集 RMSE（见 Q5） |
| **数据泄漏（划分泄漏）** | 不同 run 使用不同划分，导致 test 集样本出现在某些 run 的训练集 | 使用 `reuse_split_from` 强制复用相同划分；划分 CSV 持久化到 `split_repo`（key="v2"） |
| **评估指标与训练目标耦合** | MSE 训练 + RMSE 评估存在软性循环（见 Q4） | 同时报告 MAE / R²；监控清洗率；F/G 消融组交叉验证 |
| **共线性（rho 与温度）** | 空气密度与温度高度相关，可能与风速季节模式混淆 | F/G 消融组区分"密度变化"vs"密度均值"的贡献 |
| **KNN 梯度维度不匹配** | `rho_for_clean ≠ rho_for_model` 时 clean 空间与 model 空间维度不同 | 代码已自动检测并降级为 `grad_mode=physics`（日志中会提示） |
| **样本不足** | 某台风机有效样本 < `min_train_samples`（默认 1000），会跳过 | 检查各台风机的 `n_scope`，如需降低阈值需谨慎 |
| **P_rated 估计偏差** | 额定功率由 99.5% 分位估计，若数据中存在大量限电，会低估 | 可在配置中显式设置 `prated`，或先查看功率直方图 |
| **rho 缺失值** | 气象传感器故障时 rho 为 NaN，merge 后丢失样本 | 开启 `force_drop_rho_na`（默认 true）；查看各风机 scope 数量变化 |
| **过拟合/欠拟合** | MLP 深度/宽度不适配，导致残差非平稳 | 检查 val_loss 曲线，必要时调整 `patience`/`epochs`/`hidden` |
| **tau 参数选择** | tau=0.98 意味着约 2% 的"正常点"被标记为异常 | 在论文中报告不同 tau 下的指标曲线，展示鲁棒性 |

---

## 8. 论文结构建议

### 建议章节结构

```
1. Introduction（引言）
   - 风电功率预测的重要性
   - 现有数据清洗方法的局限：忽视空气密度
   - 本文贡献（三点）

2. Related Work（相关工作）
   - 功率曲线建模综述
   - 风电数据清洗方法综述
   - 空气密度在风能领域的已有研究

3. Methodology（方法）
   3.1 空气密度计算（T, P, RH → ρ）
   3.2 两阶段清洗框架（规则 + MLP）
   3.3 KNN 局部分位阈值（三种距离度量）
   3.4 空气密度的双通道引入（rho_for_clean / rho_for_model）

4. Experiments（实验）
   4.1 数据集描述（站点、时间跨度、字段统计）
   4.2 实验设置（超参数、划分策略、评估指标说明）
   4.3 主对比实验（A/B/E 三组）
   4.4 消融研究（B/C/D/E，量化各组件贡献）
   4.5 信息有效性验证（E/F/G，排除假象）
   4.6 迭代清洗效果（E/J）

5. Discussion（讨论）
   - 密度对清洗 vs. 建模的差异化贡献
   - 评估指标的局限性讨论
   - 适用场景与局限性
   - 对实际工程的启示

6. Conclusion（结论）

Appendix（附录）
   - 超参数敏感性（tau, K, lambda_t）
   - 不同风机的个体差异分析
```

### 各实验章节的核心图表建议

| 小节 | 推荐图表 |
|------|---------|
| 4.3 主对比 | 表格：A/B/E 在 RMSE/MAE/R²/abn_rate 上的对比（干净点 vs 全量） |
| 4.4 消融 | 折线图：B→C→D→E 的 RMSE 递进改善 |
| 4.5 信息有效性 | 条形图：E vs F vs G 的 RMSE，标注误差棒（风机间方差） |
| 4.6 迭代清洗 | 柱状图：Pass1 vs Pass2 增量异常率及 RMSE 变化 |

---

## 9. 代码使用指引

### 9.1 运行消融实验

```bash
# 确保已安装依赖并准备好数据
pip install torch numpy pandas

# 运行全部实验（JSON 中顺序执行，A 必须最先）
python main.py --config experiments_paper_ablation.json
```

输出结构：

```
paper_ablation_runs/
  _splits/          # 划分缓存（复用确保公平对比）
  A_rules_only/
    JMZSFD_mlp/
      51号机/
        JMZSFD_51号机_stage2_mlp.csv
      ...
  B_no_rho/
  ...
  E_rho_both/
```

### 9.2 生成对比报告

```python
from stage2_modular.evaluation import summarize_run, compare_runs

run_names = ["A_rules_only", "B_no_rho", "C_rho_model_only",
             "D_rho_clean_only", "E_rho_both", "F_rho_shuffle",
             "G_rho_constant", "J_one_pass_rho_both"]

# 对外指标使用 test 集（独立于早停，无模型选择偏差）
results = {
    name: summarize_run(f"paper_ablation_runs/{name}", split="test")  # ← test，非 val
    for name in run_names
}

# 主对比表格
table = compare_runs(results)
print(table.to_markdown())   # 可直接粘贴到 Markdown 文档

# 含全量点的 RMSE（用于 Q4 中的循环性检验）
results_all = {
    name: summarize_run(f"paper_ablation_runs/{name}", split="test",
                        exclude_abn=False)
    for name in run_names
}
table_all = compare_runs(results_all, metric_keys=["rmse", "mae", "r2", "n_samples"])
print("=== 全量测试集 RMSE（含异常标记点）===")
print(table_all.to_markdown())
```

### 9.3 关键配置参数说明

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `rho_for_clean` | false | KNN 清洗是否使用密度作为特征 |
| `rho_for_model` | false | MLP 建模是否使用密度作为输入 |
| `rho_input_mode` | `"normal"` | `normal`/`shuffle`/`constant`，控制消融实验 |
| `cleaning_passes` | 2 | 迭代清洗次数，0=仅规则，1=单次，2=两次 |
| `thresholds.tau_hi` / `tau_lo` | 0.98 | 上/下分位置信水平，越大阈值越宽松（检出越少） |
| `thresholds.k_nei` | 500 | KNN 邻居数，越大越平滑但计算越慢 |
| `thresholds.lambda_t` | 6.0 | tanorm 度量中切向权重，0=纯法向，∞=纯欧氏 |
| `split.strategy` | `"shuffle"` | 划分策略：`shuffle`/`time`/`block_shuffle` |
| `split.ratio` | `[0.70, 0.15, 0.15]` | 训练/验证/测试比例；验证用于早停，测试用于最终指标 |

---

## 附：实验间依赖关系

```
A_rules_only（生成基准划分）
  ├── B_no_rho          (reuse_split_from: A)
  ├── C_rho_model_only  (reuse_split_from: A)
  ├── D_rho_clean_only  (reuse_split_from: A)
  ├── E_rho_both        (reuse_split_from: A)
  ├── F_rho_shuffle     (reuse_split_from: A)
  ├── G_rho_constant    (reuse_split_from: A)
  └── J_one_pass_rho_both (reuse_split_from: A)
```

> **建议**：运行实验时按 JSON 中的顺序执行（A 必须最先），后续实验会自动加载 A 的划分缓存。

---

*本报告 v2.2 在 v2.1 基础上新增了 Q6 问答（风机结果缺失的根因分析：turbine_start/turbine_end 范围不完整），并在 `orchestrator.py` 中实现了 turbine_auto_discover 功能，使配置文件中无需手动维护风机编号范围。*
